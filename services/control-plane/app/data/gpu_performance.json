{
    "RTX 4090": {
        "vram_gb": 24,
        "performance_score": 100,
        "compute_capability": "8.9",
        "tdp_watts": 450,
        "alternatives": [
            {
                "gpu": "RTX 4080",
                "performance_ratio": 0.85,
                "use_case": "Good for inference, 15% slower, lower power consumption"
            },
            {
                "gpu": "A100",
                "performance_ratio": 1.5,
                "use_case": "Better for training, 50% faster, more VRAM (40GB/80GB)"
            },
            {
                "gpu": "RTX 3090",
                "performance_ratio": 0.7,
                "use_case": "Budget option, 30% slower, similar VRAM"
            }
        ]
    },
    "RTX 4080": {
        "vram_gb": 16,
        "performance_score": 85,
        "compute_capability": "8.9",
        "tdp_watts": 320,
        "alternatives": [
            {
                "gpu": "RTX 4090",
                "performance_ratio": 1.18,
                "use_case": "20% faster, more VRAM, higher cost"
            },
            {
                "gpu": "RTX 3080",
                "performance_ratio": 0.75,
                "use_case": "Budget option, 25% slower"
            }
        ]
    },
    "A100": {
        "vram_gb": 40,
        "performance_score": 150,
        "compute_capability": "8.0",
        "tdp_watts": 400,
        "alternatives": [
            {
                "gpu": "A100 80GB",
                "performance_ratio": 1.0,
                "use_case": "Same performance, double VRAM for large models"
            },
            {
                "gpu": "RTX 4090",
                "performance_ratio": 0.67,
                "use_case": "Consumer GPU, lower cost, less VRAM"
            },
            {
                "gpu": "H100",
                "performance_ratio": 3.0,
                "use_case": "Next-gen, 3x faster, highest cost"
            }
        ]
    },
    "RTX 3090": {
        "vram_gb": 24,
        "performance_score": 70,
        "compute_capability": "8.6",
        "tdp_watts": 350,
        "alternatives": [
            {
                "gpu": "RTX 4090",
                "performance_ratio": 1.43,
                "use_case": "Newer generation, 43% faster"
            },
            {
                "gpu": "RTX 3080",
                "performance_ratio": 0.86,
                "use_case": "Slightly slower, less VRAM (10GB)"
            }
        ]
    },
    "H100": {
        "vram_gb": 80,
        "performance_score": 450,
        "compute_capability": "9.0",
        "tdp_watts": 700,
        "alternatives": [
            {
                "gpu": "A100 80GB",
                "performance_ratio": 0.33,
                "use_case": "Previous gen, 1/3 speed, lower cost"
            },
            {
                "gpu": "RTX 4090",
                "performance_ratio": 0.22,
                "use_case": "Consumer GPU, much lower cost"
            }
        ]
    },
    "V100": {
        "vram_gb": 32,
        "performance_score": 50,
        "compute_capability": "7.0",
        "tdp_watts": 300,
        "alternatives": [
            {
                "gpu": "A100",
                "performance_ratio": 3.0,
                "use_case": "Newer generation, 3x faster"
            },
            {
                "gpu": "RTX 3090",
                "performance_ratio": 1.4,
                "use_case": "Consumer GPU, 40% faster, similar VRAM"
            }
        ]
    }
}